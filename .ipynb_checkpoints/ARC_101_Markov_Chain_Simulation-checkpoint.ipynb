{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gold\"> A delicious Markov Chain </h1>\n",
    "\n",
    "<img src=\"./images/delicious_MC.png\" width=\"570\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Burger : 0, Pizza : 1, Hotdog : 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Burger', 1: 'Pizza', 2: 'Hotdog'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = {\n",
    "    0 : \"Burger\",\n",
    "    1 : \"Pizza\",\n",
    "    2 : \"Hotdog\"\n",
    "}\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gold\">Transition Matrix</h1>\n",
    "<img src=\"./images/mat2.png\" width=\"240\" height=\"120\">\n",
    "\n",
    "## A_ij = P(X_n = j | X_n-1 = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2, 0.6, 0.2],\n",
       "       [0.3, 0. , 0.7],\n",
       "       [0.5, 0. , 0.5]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[0.2, 0.6, 0.2], [0.3, 0.0, 0.7], [0.5, 0.0, 0.5]])\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gold\"> Random Walk on Markov Chain</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is a simple implementation of a **Markov Chain**. A Markov Chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.\n",
    "\n",
    "Here's a detailed breakdown of the code:\n",
    "\n",
    "1. `state` is a dictionary that maps integers to food items. It's used to represent the states in the Markov Chain.\n",
    "\n",
    "2. `A` is a 2D numpy array that represents the **transition matrix**. Each entry `A[i][j]` represents the probability of transitioning from state `i` to state `j`. For example, `A[0][1]` is the probability of transitioning from \"Burger\" to \"Pizza\".\n",
    "\n",
    "3. `n` is the number of transitions you want to simulate in the Markov Chain.\n",
    "\n",
    "4. `start_state` is the initial state of the Markov Chain. In this case, it starts at state 0, which is \"Burger\".\n",
    "\n",
    "5. `curr_state` is a variable that keeps track of the current state in the Markov Chain.\n",
    "\n",
    "6. The `print` statement prints the initial state.\n",
    "\n",
    "7. The `while` loop simulates `n` transitions in the Markov Chain. In each iteration, it uses `np.random.choice` to pick a new state based on the transition probabilities in `A`. It then prints the new state and decrements `n`.\n",
    "\n",
    "8. Finally, it prints \"stop\" to indicate the end of the simulation.\n",
    "\n",
    "So, this code is essentially simulating a customer's order pattern where the next item they order only depends on what they ordered previously. The order pattern is random and follows the probabilities defined in the transition matrix `A`. The simulation runs for `n` orders starting from \"Burger\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burger ---> Pizza ---> Hotdog ---> Hotdog ---> Hotdog ---> Burger ---> Burger ---> Pizza ---> Hotdog ---> Hotdog ---> Burger ---> Burger ---> Burger ---> Hotdog ---> Burger ---> stop\n"
     ]
    }
   ],
   "source": [
    "n = 15\n",
    "start_state = 0\n",
    "curr_state = start_state\n",
    "print(state[curr_state], \"--->\", end=\" \")\n",
    "\n",
    "while n-1:\n",
    "    curr_state = np.random.choice([0, 1, 2], p=A[curr_state])\n",
    "    print(state[curr_state], \"--->\", end=\" \")\n",
    "    n-=1\n",
    "print(\"stop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gold\">Approach 1 : Monte Carlo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is an extension of the previous Markov Chain simulation. It's used to estimate the **steady-state probabilities** of the Markov Chain, often denoted by `π`.\n",
    "\n",
    "Here's a detailed breakdown of the code:\n",
    "\n",
    "1. `steps` is the total number of transitions you want to simulate in the Markov Chain. In this case, it's set to `10**6`, or one million transitions.\n",
    "\n",
    "2. `start_state` is the initial state of the Markov Chain. It starts at state 0, which is \"Burger\".\n",
    "\n",
    "3. `curr_state` is a variable that keeps track of the current state in the Markov Chain.\n",
    "\n",
    "4. `pi` is a numpy array that will keep track of the number of times each state is visited during the simulation. It's initialized with zeros, except for the start state, which is set to 1 because the simulation starts there.\n",
    "\n",
    "5. The `while` loop simulates `steps` transitions in the Markov Chain. In each iteration, it uses `np.random.choice` to pick a new state based on the transition probabilities in `A`. It then increments the count for the new state in `pi` and increments `i`.\n",
    "\n",
    "6. Finally, it prints the estimated steady-state probabilities by dividing `pi` by `steps`. This gives the proportion of time spent in each state, which is an estimate of the steady-state probabilities.\n",
    "\n",
    "So, this code is essentially simulating a customer's order pattern over a large number of orders and estimating the long-term proportion of orders for each food item. The order pattern is random and follows the probabilities defined in the transition matrix `A`. The simulation runs for `steps` orders starting from \"Burger\". The output `π` is the estimated probability of each state in the long run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "π =  [0.35262  0.21114  0.436241]\n"
     ]
    }
   ],
   "source": [
    "steps = 10**6\n",
    "start_state = 0\n",
    "curr_state = start_state\n",
    "pi = np.array([0, 0, 0])\n",
    "pi[start_state] = 1\n",
    "\n",
    "i = 0\n",
    "while i<steps:\n",
    "    curr_state = np.random.choice([0,1,2], p=A[curr_state])\n",
    "    pi[curr_state]+=1\n",
    "    i +=1\n",
    "\n",
    "print(\"π = \", pi/steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gold\">Approach 2 : Repeated Matrix Multiplication</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is another method to estimate the **steady-state probabilities** of a Markov Chain, often denoted by `π`. Instead of simulating transitions, it repeatedly multiplies the transition matrix `A` by itself.\n",
    "\n",
    "Here's a detailed breakdown of the code:\n",
    "\n",
    "1. `steps` is the number of times you want to multiply the transition matrix `A` by itself. In this case, it's set to `10**3`, or one thousand times.\n",
    "\n",
    "2. `A_n` is a copy of the transition matrix `A` that will be updated in each iteration.\n",
    "\n",
    "3. The `while` loop performs the matrix multiplication. In each iteration, it multiplies `A_n` by `A` using `np.matmul` and assigns the result back to `A_n`. It then increments `i`.\n",
    "\n",
    "4. After the loop, `A_n` is essentially `A` raised to the power of `steps`. It prints `A_n`.\n",
    "\n",
    "5. Finally, it prints the first row of `A_n` as the estimated steady-state probabilities. This is based on the theory that as `n` goes to infinity, every row of `A^n` converges to the steady-state probabilities.\n",
    "\n",
    "So, this code is essentially estimating the long-term proportion of orders for each food item based on the transition probabilities defined in the transition matrix `A`. The output `π` is the estimated probability of each state in the long run. This method is more mathematical and less stochastic compared to the simulation method in the previous code. It's also faster and more accurate when the number of steps is large. However, it requires more computational resources as the size of the transition matrix increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A^n = \n",
      " [[0.35211268 0.21126761 0.43661972]\n",
      " [0.35211268 0.21126761 0.43661972]\n",
      " [0.35211268 0.21126761 0.43661972]] \n",
      "\n",
      "π =  [0.35211268 0.21126761 0.43661972]\n"
     ]
    }
   ],
   "source": [
    "steps = 10**3\n",
    "A_n = A\n",
    "\n",
    "i=0\n",
    "while i<steps:\n",
    "    A_n =  np.matmul(A_n, A)\n",
    "    i+=1\n",
    "\n",
    "print(\"A^n = \\n\", A_n, \"\\n\")\n",
    "print(\"π = \", A_n[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gold\">Approach 3 : Finding Left Eigen Vectors</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is using the `scipy.linalg.eig` function to compute the **eigenvalues** and **left eigenvectors** of the transition matrix `A`.\n",
    "\n",
    "Here's a detailed breakdown of the code:\n",
    "\n",
    "1. `scipy.linalg.eig(A, right = False, left = True)` is a function call that computes the eigenvalues and left eigenvectors of `A`. The `right = False` argument means that right eigenvectors should not be computed, and the `left = True` argument means that left eigenvectors should be computed.\n",
    "\n",
    "2. `values, left` is where the results of the function call are stored. `values` is a 1D array containing the eigenvalues of `A`, and `left` is a 2D array where the columns are the corresponding left eigenvectors.\n",
    "\n",
    "3. The `print` statements print the left eigenvectors and eigenvalues.\n",
    "\n",
    "In the context of Markov Chains, the left eigenvector corresponding to the eigenvalue 1 (if it exists) gives the steady-state probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left eigen vectors = \n",
      " [[-0.58746336+0.j         -0.16984156-0.35355339j -0.16984156+0.35355339j]\n",
      " [-0.35247801+0.j          0.67936622+0.j          0.67936622-0.j        ]\n",
      " [-0.72845456+0.j         -0.50952467+0.35355339j -0.50952467-0.35355339j]] \n",
      "\n",
      "eigen values = \n",
      " [ 1.  +0.j        -0.15+0.3122499j -0.15-0.3122499j]\n"
     ]
    }
   ],
   "source": [
    "import scipy.linalg\n",
    "values, left = scipy.linalg.eig(A, right = False, left = True)\n",
    "\n",
    "print(\"left eigen vectors = \\n\", left, \"\\n\")\n",
    "print(\"eigen values = \\n\", values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code normalizes the left eigenvector corresponding to the eigenvalue 1 to get the steady-state probabilities.\n",
    "\n",
    "Here's a detailed breakdown of the code:\n",
    "\n",
    "1. `pi = left[:,0]` extracts the first column of `left`, which is the left eigenvector corresponding to the first eigenvalue (which should be 1 for a stochastic matrix like `A`).\n",
    "\n",
    "2. `pi_normalized = [(x/np.sum(pi)).real for x in pi]` normalizes `pi` so that its elements sum to 1. This is done by dividing each element of `pi` by the sum of all elements in `pi`. The `.real` part is used to discard any imaginary part due to numerical errors, as the probabilities should be real numbers.\n",
    "\n",
    "3. `pi_normalized` is the normalized steady-state probabilities. It's not printed in the code, but it would be the output if you run this line in a Python environment.\n",
    "\n",
    "So, this code is essentially computing the long-term proportion of orders for each food item based on the transition probabilities defined in the transition matrix `A`. The output `pi_normalized` is the estimated probability of each state in the long run. This method is more mathematical and less stochastic compared to the simulation method or the matrix multiplication method. It's also faster and more accurate when the number of steps is large. However, it requires more computational resources as the size of the transition matrix increases. It also requires that the Markov Chain is ergodic (i.e., it's possible to go from any state to any other state), and it may not work if the transition matrix has certain properties (like being defective or non-diagonalizable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3521126760563379, 0.21126760563380298, 0.43661971830985913]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = left[:,0]\n",
    "pi_normalized = [(x/np.sum(pi)).real for x in pi]\n",
    "pi_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:gold\">P(Pizza --> Hotdog --> Hotdog --> Burger) = ?</h1>\n",
    "<br>\n",
    "\n",
    "## => P(X_0 = Pizza, X_1 = Hotdog, X_2 = Hotdog, X_3 = Burger)\n",
    "## => P(X_0 = Pizza)  P(X_1 = Hotdog | X_0 = Pizza)  P(X_2 = Hotdog | X_1 = Hotdog)  P(X_3 = Burger | X_2 = Hotdog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a function `find_prob` that calculates the probability of a given sequence of states in a Markov Chain, given the transition matrix `A` and the initial state probabilities `pi`.\n",
    "\n",
    "Here's a detailed breakdown of the code:\n",
    "\n",
    "1. `seq` is the sequence of states for which you want to find the probability.\n",
    "\n",
    "2. `start_state` is the first state in the sequence.\n",
    "\n",
    "3. `prob` is initialized to the probability of the start state, which is `pi[start_state]`.\n",
    "\n",
    "4. `prev_state` and `curr_state` are variables that keep track of the previous state and current state in the sequence.\n",
    "\n",
    "5. The `for` loop iterates over the rest of the sequence. In each iteration, it updates `curr_state` to the next state in the sequence, multiplies `prob` by the transition probability from `prev_state` to `curr_state`, and then updates `prev_state` to `curr_state`.\n",
    "\n",
    "6. The function returns `prob`, which is the probability of the sequence `seq`.\n",
    "\n",
    "The `print` statement at the end calls `find_prob` with a specific sequence `[1, 2, 2, 0]`, the transition matrix `A`, and the steady-state probabilities `pi_normalized`. It prints the probability of this sequence.\n",
    "\n",
    "So, this code is essentially calculating the probability of a specific order pattern for the food items based on the transition probabilities defined in the transition matrix `A` and the initial state probabilities `pi_normalized`. The output is the probability of the sequence `[1, 2, 2, 0]`, which corresponds to the order pattern \"Pizza\" -> \"Hotdog\" -> \"Hotdog\" -> \"Burger\". This can be useful for predicting the likelihood of future order patterns based on the observed transition probabilities and initial state probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03697183098591552\n"
     ]
    }
   ],
   "source": [
    "def find_prob(seq, A, pi):\n",
    "    start_state = seq[0]\n",
    "    prob = pi[start_state]\n",
    "    prev_state, curr_state = start_state, start_state\n",
    "    for i in range(1, len(seq)):\n",
    "        curr_state = seq[i]\n",
    "        prob *= A[prev_state][curr_state]\n",
    "        prev_state = curr_state\n",
    "    return prob\n",
    "\n",
    "print(find_prob([1, 2, 2, 0], A, pi_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END of markov simulation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
